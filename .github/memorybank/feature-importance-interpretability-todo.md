# To-Do List: Feature Importance Interpretability (SHAP/LIME)

## Status: In Progress


### Steps:
- [x] 1. Review plan and best practices for interpretability integration
- [x] 2. Add SHAP feature importance visualization for TabNet model
- [ ] 3. Add LIME feature importance visualization for TabNet model
- [x] 4. Save SHAP and LIME plots to visualizations/ (plots are now only saved, not shown)
- [ ] 5. Update memory bank and To-Do list after each step
- [ ] 6. Document interpretability code and update best practices if needed
- [ ] 7. Validate outputs and confirm with user

---

**Next Action:**
- Step 3: Add LIME feature importance visualization for TabNet model in src/main.py
